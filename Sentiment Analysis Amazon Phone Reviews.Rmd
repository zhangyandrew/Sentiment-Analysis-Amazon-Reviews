---
title: "Sentiment Analysis for Amazon Phone Reviews"
author: "Andrew Zhang"
date: "12/3/2018"
output: pdf_document
---

# Abstract
Amazon is a huge marketplace for a variety of products, ranging from school material to beauty care. With such a huge customer base, each of the products has an option for reviews. Looking specifically at phones, we are interested in any patterns associated with mobile phone reviews. In addition, we want to see whether or not the number of words per review follows the benford distribution. Following our analysis, we were able to conclude that there is a stark difference between negative and positive reviews in terms of word counts and word types.

# Background
Amazon has been expanding their market reaches to almost every industry in the world and the mobile device industry is no exception. Amazon has been marketing cellular devices from a wide variety of companies such as Apple and Samsung. What makes Amazon unique is the fact that every product has readily available reviews from previous customers, whereas, company sites such as Apple, do not include such reviews. However, we are curious as to how useful these reviews are and whether or not they are genuine. For this project, we utilize sentiment analysis to explore the general characteristics of reviews and apply Benford analysis to determine the validity of these reviews. 

```{r, include = FALSE}
setwd("/Users/andrewzhang/Desktop/School/Graduate/MA615/MA615 Final Project")
amazon <- read.csv("Amazon_Unlocked_Mobile.csv")
```

# Variables
```{r, include = FALSE}
library(knitr)
variable_names <- colnames(amazon)
descriptions <- c('Name of the Product',
'Company that created the product',
'Amount of money for the product',
'Rating a customer gives the product(Out of 5)',
'Written comments regarding the product',
'Number of votes a review gets')
var_table <- data.frame(variable_names, descriptions)
```

```{r, echo = FALSE}
kable(var_table, caption = "Variables")
```

```{r, subset, include = FALSE}
library(caret)
library(dplyr)

amazon$Brand.Name <- tolower(as.character(amazon$Brand.Name))

amazon_counts <- amazon %>% 
  count(Product.Name, sort = TRUE)

amazon_counts2 <- amazon %>% 
  count(Brand.Name, sort = TRUE)

brand_counts <- amazon %>% 
  group_by(Product.Name) %>% 
  count(Product.Name, sort = TRUE) 

sub <- brand_counts[brand_counts$n > 800,]

amazon_sub <- amazon[amazon$Product.Name %in% sub$Product.Name, ]

amazon_sub <- amazon_sub %>% 
  group_by(Product.Name) %>% 
  mutate(id = row_number())

amazon_sub$Brand.Name[amazon_sub$Brand.Name == "samsung korea ltd"] <- "samsung"
```

```{r, include = FALSE}
library(tidyverse)
str(amazon_sub)

amazon_sub[amazon_sub$Brand.Name == "",] <- NA
colSums(is.na(amazon_sub))
amazon_sub <- na.omit(amazon_sub)

brand_counts <- amazon_sub %>% 
  group_by(Brand.Name) %>% 
  summarize(Count = length(Brand.Name))

length(unique(amazon_sub$Product.Name))
length(unique(amazon_sub$Brand.Name))

new <- c()
new <- data.frame(lapply(amazon_sub$Reviews, as.character), stringsAsFactors = FALSE)
trans_new <- t(new)
amazon_sub$Reviews <- trans_new[1:54198]

amazon_sub$Word_Count <- sapply(strsplit(amazon_sub$Reviews, " "), length)

amazon_explore <- amazon_sub %>% 
  group_by(Product.Name, Brand.Name) %>% 
  summarize(Price.Avg = mean(Price),
            Rating.Avg = mean(Rating),
            ReviewVotes.Avg = mean(Review.Votes),
            WordCount.Avg = mean(Word_Count))
```

```{r, include = FALSE}
install.packages("corrplot", repos='http://cran.us.r-project.org')
library(corrplot)

cor_sub <- amazon_explore %>% 
  select(Price.Avg, Rating.Avg, ReviewVotes.Avg, WordCount.Avg)
cor_sub$Product.Name <- NULL

amazon_cor <- cor(cor_sub)
```

# Data Cleaning/Exploration
First and foremost, we looked at the structure of the data to ensure each variable was the proper type. Then we proceeded to remove any missing observations. Then, utilizing sentiment analysis, we split the reviews into words, removed stop words, and counted up the words per review. We then, added positive and negative sentiments to determine the general characteristics for both types of sentiments. For the sake of exploration, we aggregated each of the observations by review number in order to make exploratory data analysis easier. Finally, because there were so many words being tokenized, we filtered the data to include only the biggest brands or brands with reviews that counted more than 800. 

```{r, echo = FALSE, fig.align="center"}
corrplot(amazon_cor, method = "ellipse")
```

We want to look at the variables to see which of the variables are correlated with one another, whether it be trivially or not. Above, we can see that Ratings and Prices are slightly correlated while Word Counts and Review Votes are also correlated. Being positively correlated means that there is a positive relationship where an increase in one variable would mean an increase in the other. Meanwhile, Ratings and Review Votes are negatively correlated, meaning an increase in ratings would mean a decrease in number of review votes. This is something we should pay attention and will discuss further in the analysis. 

Next, we will look at some exploratory plots for the aggregated data. 

```{r, exploratory plots, include = FALSE}
library(ggpubr)
library(magrittr)
ep1 <- ggplot(amazon_explore) +
  aes(ReviewVotes.Avg, Rating.Avg) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_minimal() +
  labs(title = "Review Votes vs. Ratings")

ep2 <- ggplot(amazon_explore) +
  aes(log(Price.Avg), Rating.Avg) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_minimal() +
  labs(title = "Price vs. Rating")

ep3 <- ggplot(amazon_explore) +
  aes(log(WordCount.Avg), Rating.Avg) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_minimal() +
  labs(title = "Word Counts vs. Rating")

ep4 <- ggplot(amazon_explore) +
  aes(log(Price.Avg), log(WordCount.Avg)) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_minimal() +
  labs(title = "Price vs. Word Count")
```

```{r, echo = FALSE, out.width = "85%", fig.align="center"}
ggarrange(ep1, ep2, ep3, ep4, ncol=2, nrow = 2)
```

From the graphs above, it is difficult to make any conclusions between any of these variables as, even though the regression line points in a certain direction, there is too much noise and variance in the datapoints to soundly conclude a positive or negative relationship between variables. 

```{r, sentiment analysis, include = FALSE}
library(tidytext)
colnames(amazon_sub)[5] <- c("text")
review_words <- amazon_sub %>% unnest_tokens(output = word, input = text)

data("stop_words")
tidy_words <- review_words %>%
  anti_join(stop_words)
```

```{r, get positive/negative, include = FALSE}
afinn <- get_sentiments("afinn")
nrc <- get_sentiments("nrc")
bing <- get_sentiments("bing")

rw_bing <- tidy_words %>% 
  inner_join(bing)

rw_bingafinn <- rw_bing %>% 
  inner_join(afinn, by = "word")

## Explore number of positive words and negative words
rw_explore <- rw_bingafinn %>% 
  group_by(Product.Name, Brand.Name, sentiment) %>% 
  summarize(Price.Avg = mean(Price),
            Rating.Avg = mean(Rating),
            ReviewVotes.Avg = mean(Review.Votes),
            WordCount.Avg = mean(Word_Count), 
            Score.Avg = mean(score))
```

```{r, plot sentiments, echo = FALSE, out.width = "85%", fig.align="center"}
ggplot(data = rw_explore) +
  aes(x = reorder(Product.Name, WordCount.Avg), color = sentiment, weight = WordCount.Avg) +
  geom_bar(fill = '#0c4c8a') +
  labs(title = 'Sentiment Counts',
    x = 'Product Name',
    y = 'Number of Words') +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  coord_flip()
```

We can see that, looking at the number of negative and positive words, reviews typically have more words for negative reviews than for positive reviews. 

```{r, preprocess, include = FALSE}
str(rw_bingafinn)

rw_bingafinn$Brand.Name <- factor(rw_bingafinn$Brand.Name)
rw_bingafinn$Price <- log(rw_bingafinn$Price)
rw_bingafinn$Review.Votes[rw_bingafinn$Review.Votes == 0] <- 1
rw_bingafinn$Review.Votes <- log(rw_bingafinn$Review.Votes)
rw_bingafinn$Word_Count <- log(rw_bingafinn$Word_Count)

colSums(is.na(rw_bingafinn))
rw_bingafinn <- na.omit(rw_bingafinn)
```

# Pattern Analysis
```{r, EDA, echo = FALSE, warning=FALSE, out.width = "85%", fig.align="center"}
#esquisse::esquisser(rw_bingafinn)
library(ggplot2)

ggplot(data = rw_bingafinn) +
  aes(x = Rating, y = Price, color = sentiment) +
  geom_point() +
  theme_minimal() +
  facet_wrap(vars(Brand.Name)) +
  labs(title = "Ratings vs. Price")
```

Continuing on our exploratory plots from earlier in the report, it's still hard to find clear patterns within the data. Looking at the correlated variables within the full dataset, it's hard to decipher any relationship between the variables as many of the points are the same. Examining the Ratings vs. Prices plot, we can see that the majority of the negative sentiment is on the lower end of the rating scale while the positive sentiment is on the higher end of the rating scale, indicating more positive reviews mean higher ratings while more negative reviews mean lower ratings. 

```{r, echo = FALSE, out.width = "85%", fig.align="center"}
ggplot(data = rw_bingafinn) +
  aes(x = Word_Count, y = Review.Votes, color = sentiment) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_minimal() +
  facet_wrap(vars(Brand.Name)) + 
  labs(title = "Word Count vs. Review Votes")
```

Next, if we look at the plots for the Review Votes against the Word_Counts, we can see that both negative and positive sentiments have an upward trend, which signify that more words in a review can be associated with a higher number of votes for a particular review. We also know that a larger number of words indicates a lower rating or more negative sentiment, so we can tentatively say that people vote for more negative reviews.

```{r, echo = FALSE, out.width = "85%", fig.align="center"}
ggplot(data = rw_bingafinn) +
  aes(x = Rating, y = Review.Votes, color = Brand.Name) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_minimal() +
  labs(title = "Ratings vs. Review.Votes")
```

Examining the relationship between ratings and number of review votes, we can see, for the most part, that as the ratings increased, the number of review votes decreased. From the previous plot with the relationship between word counts and the review votes, the inverse relationship here indicates a potential relationship between the number of words and ratings. 

```{r, echo = FALSE, out.width = "85%", fig.align="center"}
ggplot(data = rw_bingafinn) +
  aes(x = sentiment) +
  geom_bar(fill = '#0c4c8a') +
  theme_minimal() + 
  labs(title = "Positive vs. Negative Distribution")
```

We can see that the majority of the sentiments in the reviews are positive, which is reflective of the average rating of the reviews, 3.87/5. 

```{r, echo = FALSE, out.width = "85%", fig.align="center"}
ggplot(data = rw_bingafinn) +
  aes(x = Word_Count, color = sentiment) +
  geom_histogram(bins = 30, fill = '#0c4c8a') +
  labs(title = 'Distribution of Word Counts') +
  theme_minimal() +
  facet_wrap(vars(Brand.Name))
```

From this particular plot, we can see that the number of words is significantly more for negative sentiments than for positive sentiments. In addition, we can see that Samsung and Blu have the most reviews amongst the groups. This could be attributed to company popularity. 

```{r, plots, echo = FALSE}
words_brand <- tidy_words %>% 
  group_by(Brand.Name) %>% 
  count(word, sort = TRUE)

words_count <- tidy_words %>% 
  group_by(word) %>% 
  count(word, sort = TRUE)

words_count %>%
  filter(n > 2900) %>% 
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(fill = '#0c4c8a') +
  xlab(NULL) +
  labs(title = "Most Popular Words") +
  coord_flip()
```

Looking at the most popular words, we can see that the word *phone* is easily the most used word form the figure above. However, if we look at the words in this list of 20, we can see lots of the words are reflective of the features that people look for prior to phone purchases. These words include:

- *Screen*
- *Battery*
- *Camera*
- *Sim*
- *apps*

Interestingly, we can also see the word *iphone* and *samsung* on the list. Although we filtered the brands to only reflect the most popular brands, we can see that two of the most popular brands are Apple and Samsung as many people include the product/brand name in their reviews. 

```{r, bing word count, include = FALSE}
bing_word_counts <- tidy_words %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```

```{r, echo = FALSE}
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = reorder(word, n), y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
```

From the figure above, we look at the words that contribute the most to the bing sentiment. Looking at the positive graph, we can see that, most of these words are subjective towards the phone; love, nice, pretty, etc. If we look at the negative graph, most of these words are related to technical aspects of these phones; slow, lag, issues, cheap, etc. This helps show the focus of both positive and negative reviews, where positive reviews are often subjective and emotionally driven, while negative reviews are harsh criticisms on the device features. 

```{r, include = FALSE}
install.packages("benford.analysis", repos='http://cran.us.r-project.org')
library(benford.analysis)
library(tidyverse)

## Product Counts
revcounts <- amazon_counts$n

revcounts_b <- benford(revcounts)

chisq(revcounts_b)

## Brand Counts
revcounts2 <- amazon_counts2$n

revcounts_b2 <- benford(revcounts2)

chisq(revcounts_b2)
```

# Benford Analysis
### Benford Analysis for Product Names
```{r, echo = FALSE, out.width = "85%", fig.align="center"}
plot(revcounts_b)
```

### Benford Analysis for Brand Names
```{r, echo = FALSE, out.width = "85%", fig.align="center"}
plot(revcounts_b2)
```

Looking at the Benford analysis, we can see that the data does not follow a benford distribution as there are spikes throughout the data. It is possible that falsely generated reviews or "meme" reviews were written for these devices. 

# Conclusion
Utilizing the initial correlation plot, we discovered potential positive relationships between ratings/price and review votes/word count, while there is a potential negative relationship between ratings/review votes. Looking at the general trends, we were able to conclude several things about the data. 

First, the number of words in a negative review is significantly more than the number of words in a positive review. If we think back to all of the times we browsed amazon reviews, most of the time, people have more to say about why a product is dysfunctional and why they don't particularly enjoy it, whereas, positive reviews are typically along the lines of "Great product" or "I love it", rather than a detailed explanation of why the individual enjoys the product. 

Second, we also discovered that the number of review votes were associated with the word counts of reviews. The more words a review had, the more votes the particular review had. Since we know that negative reviews had more words per review than positive reviews, we can associate negative reviews with a larger number of review votes. This makes sense as, when people scroll thorugh reviews looking for sincere reviews regarding products, many are not going to take "I love it" seriously. However, an individual who comments on how poor the camera quality of the phone might be or how poor the battery life is, will likely get more votes as others will find the review more helpful. 

Lastly, utilizing the previous two conclusions regarding number of review votes being associated with word counts and negative ratings having more words per review, we can draw the conclusion that negative ratings have more words per review, which follows the negative correlation displayed in the correlation plot.

On top of negative vs. positive reviews, we can look at company specific reviews. If we look at the distribution of word counts divided by companies in the plot earlier in the report, we can see there is a significant difference in how reviews are distributed. We expect larger companies like Apple and Samsung to dominate the board, however, we really only see Samsung and Blu. Apple doesn't a significantly large number of mobile reviews even though the iPhone is one of the most popular phones in the world. Doing some research, both Samsung and Blu have had issues with their phones recently. As we all know, Samsung had the exploding phone issue not too long ago, while Blu has recently been dealing with public backlash for chinese spyware on their phones. With such issues, we might come to the conclusion that people are filling more and more complaints against these companies for any tiny issues with their mobile devices. 

In regards to the Benford analysis, we can see that per both number of reviews per product and number of reviews per brand, neither follow a Benford distribution. Now, if we think about it, going through reviews, often times, we can find reviews that are insincere or fake, where people either write something as a joke or there is a computer automated response that makes no sense. It is possible that these sorts of responses skew the distribution of the data slightly. Something like this is worth looking into more detail about. 

# Future Works
One of the things we can potentially look at is a more in-depth review of each of the phone brands. Companies like Samsung, Apple, and LG are bound to have significantly different reviews and types of reviews compared to one another. 

Another aspect worth looking into is creating a model for predicting either ratings or prices based on a combination of variables such as review votes, word counts, sentiment score, etc. It would be interesting to see if an universal model exists for how different brands price their phones and whether or not they take into consideration the public opinion on their devices. 

# Acknowledgement
Special thank you to Professor Wright for spending so much time teaching and creating so many unique assignments and projects this semester. 

# Shiny App

```{r, shiny}
library(shiny)
library(ggpubr)

# Define UI ----
ui <- fluidPage(
     titlePanel("Sentiment Reviews per Phone"),
      # Input: Slider for the number of bins ----
     sidebarLayout(
       sidebarPanel(
         selectInput(inputId = "Top.Brand.Name", label = "Mobile Phone Brands",
                     choices = unique(amazon_sub$Brand.Name),
                 helpText("Choose which brand you'd like to observe"), 
                 multiple = FALSE)
       ),
     mainPanel(
       plotOutput("plot")
       )
     )
)

# Define server logic ----
server <- function(input, output, session) {
  afinn4 <- reactive(tidy_words %>%
  filter(Brand.Name == input$Top.Brand.Name) %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = id) %>% 
  summarize(sentiment = sum(score)) %>% 
  mutate(method = "AFINN"))
  
  bing_and_nrc4 <- reactive(bind_rows(tidy_words %>% 
                               filter(Brand.Name == input$Top.Brand.Name) %>% 
                               inner_join(get_sentiments("bing")) %>%
                               mutate(method = "Bing et al."),
                             tidy_words %>% 
                               inner_join(get_sentiments("nrc") %>% 
                                            filter(sentiment %in% 
                                                     c("positive", 
                                                       "negative"))) %>% 
                               filter(Brand.Name == input$Top.Brand.Name) %>% 
                               mutate(method = "NRC")) %>% 
    count(method, index = id, sentiment) %>% 
    spread(sentiment, n, fill = 0) %>% 
    mutate(sentiment = positive - negative))
  output$plot <- renderPlot(
    ggplot(bind_rows(afinn4(), bing_and_nrc4()), aes(index, sentiment, fill = 
                                                   method)) +
      geom_col(show.legend = FALSE) +
      facet_wrap(~method, ncol = 1, scales = "free_y")
    )
}

# Run the app ----
shinyApp(ui = ui, server = server)
```